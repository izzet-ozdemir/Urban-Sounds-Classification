{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv  #OpenCV Kütüphanesi\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: Pickle : Elimdeki dosyaları bilgisayarıma kaydetmeme yarayan bir kütüphane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed : 2500 / Error : 0"
     ]
    }
   ],
   "source": [
    "xPath = \"../Data_Project/Spectrograms\"\n",
    "images = []\n",
    "\n",
    "number_to_error = 0\n",
    "number_to_processed = 0\n",
    "\n",
    "errors_file = open(\"images_errors.txt\",\"w\")\n",
    "limit = 0\n",
    "for classid in os.listdir(xPath):\n",
    "    #print(classid)\n",
    "    path_to_class = f\"{xPath}/{classid}\"\n",
    "    for image in os.listdir(path_to_class):\n",
    "        if limit >= 2500:\n",
    "            break\n",
    "        try:\n",
    "            path_to_image = f\"{path_to_class}/{image}\"\n",
    "            #print(f\"{path_to_image}\")\n",
    "            img = cv.imread(path_to_image, 0)\n",
    "            img = cv.resize(img, (128,128))  #resizeing yapıyoruz.\n",
    "            img = img/255  #normalizasyon yapıyoruz.\n",
    "            images.append([img, int(classid)])\n",
    "        except Exception as e:\n",
    "            number_to_error += 1\n",
    "            errors_file.write(f\"{number_to_processed} --- {e}\")\n",
    "        finally:\n",
    "            number_to_processed += 1\n",
    "\n",
    "        print(f\"\\rProcessed : {number_to_processed} / Error : {number_to_error}\", end=\"\")\n",
    "        limit += 1\n",
    "errors_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not 1 : Neden resize yapıyoruz? : Çünkü boyutu küçülterek kolay ve hızlı işlem yapma imkanımızı artırıyouz. Elbette resimde bazı kaıplar oluşuyor ancak bunlar kabul edilebilir kayıplar. Resmin özniteliğini bozmadan oluşan kayıplara karşı daha başka imkanlar elde edebiliyoruz. Bu da projeden projeye değişebilen bir faktör. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not 2 : Neden spectrogramları siyah beyaz a çeviriyoruz? Örnek çalışmada yer alan değişkenlerden : img.shape --> (374, 500, 3)  (renkli)  --> 374 x 500 x 3 = 561.000 okunacak pixel sayısı | img_gray.shape -->(374,500)  (siyah-Beyaz) --> 374 x 500 = 187.000 okunacak pixel sayısı | Siyah beyaz specktrogramlarda aynı öznitelikteki resimleri her hangi bir kayba uğramadan 3 kat az pixel sayısına göre işlem yapılabildiği iiçin tercih ediyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not 3 : Normalizasyon Nedir? - Bir veri setinin 0 ile 1 arasına tüm değerlerinin getirilmiş olmasıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Örnek Çalışma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv.imread(\"../Data_Project/Spectrograms/0/100852-0-0-0.png\",1)\n",
    "#img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#img.shape\n",
    "\n",
    "#cv.imshow(\"frame\",img)\n",
    "#cv.imshow(\"frame_gray\",img_gray)\n",
    "#cv.waitKey(0)\n",
    "#cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not : images değerini 10 kere karıştırıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for image, classid in images:\n",
    "    X.append(image)\n",
    "    y.append(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: Elimizdeki veriyi train, validation ve test verisi olarak bölelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:2000]\n",
    "y_train = y[:2000]\n",
    "\n",
    "X_val = X[2000:2250]\n",
    "y_val = y[2000:2250]\n",
    "\n",
    "X_test = X[2250:]\n",
    "y_test = y[2250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: Bulduğumuz değerleri Numpy dizisine çevirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadece tek bir görüntüyü yazdırırsak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüntülerin tamamını yazdırırsak : 2000 görsel var ve boyutlar 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: TensorFlow da tf.keras.layers.Conv2D altında bizden istenilen argümanlar içerisinde kanal sayısı da var. Bu nedenle elimizdeki dataya kanal sayısı ekliyoruz.\n",
    "reshape metodunda -1 konulduğunda sample sayısı bilinmiyoruz demektir. reshape bunu kendisi belirler. Burada aslında 2000 yazabilirdik. Ama bilmediğimizi farzediyoruz.\n",
    "Bizden \"sample sayısı\", \"genişlikler\", \"yükseklikler\" ve \"kanal sayısı\" olarak belirtmemiz isteniyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,128,128,1)\n",
    "X_val = X_val.reshape(-1,128,128,1)\n",
    "X_test = X_test.reshape(-1,128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pickles\" not in os.listdir():\n",
    "    os.mkdir(\"pickles\")\n",
    "\n",
    "with open(\"pickles/X_train.pickle\",\"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(\"pickles/y_train.pickle\",\"wb\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "\n",
    "with open(\"pickles/X_val.pickle\",\"wb\") as f:\n",
    "    pickle.dump(X_val, f)\n",
    "with open(\"pickles/y_val.pickle\",\"wb\") as f:\n",
    "    pickle.dump(y_val, f)\n",
    "\n",
    "with open(\"pickles/X_test.pickle\",\"wb\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(\"pickles/y_test.pickle\",\"wb\") as f:\n",
    "    pickle.dump(y_test, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('spyder-cf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd810f3981735d4e8ffd810dce13e5a0d00f6312535d20d6fcace6355a35308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
